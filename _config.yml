# Site
repository: Git repository where your resume will be hosted, only required if you are hosting on GitHub (eg. sproogen/modern-resume-theme)
# favicon: Directory of your favicon (eg. images/favicon.ico)(optional)

# Content configuration version
version: 2

# Personal info
name: Luo YiKai
title: Undergraduate at Hangzhou Dianzi University
email: 20330115@hdu.edu.cn
# email_title: Email (Email title override)
phone: 19157690114
# phone_title: Phone (Phone title override)
#website: Your website (eg. https://google.com)(optional)
# website_title: Web (Website title override)

# Dark Mode (true/false/never)
darkmode: false

# Social links
# twitter_username: jekyllrb
github_username:  LYK0520
# stackoverflow_username: "00000001"
# dribbble_username: jekyll
# facebook_username: jekyll
# flickr_username: jekyll
# instagram_username: jekyll
# linkedin_username: jekyll
# xing_username: jekyll
# pinterest_username: jekyll
# youtube_username: jekyll
# orcid_username: 0000-0000-0000-0000
# googlescholar_username: D847cGsAAAAJ

# Additional icon links
# additional_links:
# - title: Link name
#   icon: Font Awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&s=brands&m=free)
#   url: Link url (eg. https://google.com)
# - title: another link
#   icon: font awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&s=brands&m=free)
#   url: Link url (eg. https://google.com)

# Google Analytics and Tag Manager
# Using more than one of these may cause issues with reporting
# gtm: "GTM-0000000"
# gtag: "UA-00000000-0"
# google_analytics: "UA-00000000-0"

# About Section
# about_title: About Me (Use this to override about section title)
about_profile_image: images/profile.png # path of image which will be displayed in about section
about_content: | # this will include new lines to allow paragraphs
  Hello, my name is Luo YiKai, an undergraduate candidate in Digital Media Technology at Hangzhou Dianzi University.
  I am researching in Image and Video Systems Lab., under the supervision of Professor Yong Man Ro.
  My major research area is multi-modal representation learning and human interactive learning. 
  I am more focusing on integrating audio, video, and text modalities in human dialogue system, especially lipreading, lip-to-speech synthesis, and audio-visual speech recognition. 
  I am also interested in machine translation, speech enhancement, and speech separation using multi-modal representations.
  Write an awesome description about yourself here, this supports markdown, so you can add [links](http://foobar.com) and highlight things <mark>like this</mark>.

  You can even add paragraphs by using empty lines like this and add anything else [markdown](https://www.markdownguide.org/getting-started#what-is-markdown) supports such as
    - Lists
    - Tables
    - <a href="google.com">Links</a>
    - Images ![alt text](/images/landscape-trees.jpg "Trees")

content:
   title: Publications
    layout: text
    content: | # this will include new lines to allow paragraphs
     
      <mark>International Conference</mark>
      - *Watch or Listen: Robust Audio-Visual Speech Recognition with Visual Corruption Modeling and Reliability Scoring* <a href="https://arxiv.org/pdf/2303.08536.pdf" style="color: black;" target="_blank">[link]</a>
      
         **Joanna Hong<span>&#42;</span>**, Minsu Kim<span>&#42;</span>, Jeongsoo Choi, and Yong Man Ro **(<span>&#42;</span> equally contributed)**
         
         IEEE/CVF Conference on Computer Vision and Pattern Recognition **(CVPR), 2023**
         
      - *Lip-to-Speech Synthesis in the Wild with Multi-task Learning* <a href="https://arxiv.org/pdf/2302.08841.pdf" style="color: black;" target="_blank">[link]</a>
      
         Minsu Kim<span>&#42;</span>, **Joanna Hong<span>&#42;</span>**, and Yong Man Ro **(<span>&#42;</span> equally contributed)**
         
         IEEE International Conference on Acoustics, Speech and Signal Processing **(ICASSP), 2023**
         
      - *VisageSynTalk: Unseen Speaker Video-to-Speech Synthesis via Speech-Visage Feature Selection* <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136960445.pdf" style="color: black;" target="_blank">[link]</a>
      
        **Joanna Hong**, Minsu Kim, Yong Man Ro
        
        European Conference on Computer Vision **(ECCV), 2022**
      
      - *Visual Context-driven Audio Feature Enhancement for Robust End-to-End Audio-Visual Speech Recognition* <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/hong22_interspeech.pdf" style="color: black;" target="_blank">[link]</a>
      
        **Joanna Hong<span>&#42;</span>**, Minsu Kim<span>&#42;</span>, Daehun Yoo, and Yong Man Ro **(<span>&#42;</span> equally contributed)**
        
        **Interspeech, 2022 (Oral)**
      
      - *SyncTalkFace: Talking Face Generation with Precise Lip-syncing via Audio-Lip Memory* <a href="https://www.aaai.org/AAAI22Papers/AAAI-7528.ParkS.pdf" style="color: black;" target="_blank">[link]</a>
      
         Se Jin Park, Minsu Kim, **Joanna Hong**, Jeongsoo Choi, and Yong Man Ro
        
         AAAI Conference on Artificial Intelligence **(AAAI), 2022 (Oral)**
         
      - *Lip to Speech Synthesis with Visual Context Attentional GAN* <a href="https://proceedings.neurips.cc/paper/2021/file/16437d40c29a1a7b1e78143c9c38f289-Paper.pdf" style="color: black;" target="_blank">[link]</a>
      
         Minsu Kim, **Joanna Hong**, Yong Man Ro
        
         Conference on Neural Information Processing Systems **(NeuIPS), 2021**
         
       - *Multi-Modality Associative Bridging Through Memory: Speech Sound Recollected From Face Video* <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Kim_Multi-Modality_Associative_Bridging_Through_Memory_Speech_Sound_Recollected_From_Face_ICCV_2021_paper.pdf" style="color: black;" target="_blank">[link]</a>
      
          Minsu Kim<span>&#42;</span>, **Joanna Hong<span>&#42;</span>**, Se Jin Park, Yong Man Ro **(<span>&#42;</span> equally contributed)**
        
          IEEE/CVF International Conference on Computer Vision **(ICCV), 2021**
         
        - *Unsupervised Disentangling of Viewpoint and Residues Variations by Substituting Representations for Robust Face Recognition* <a href="https://ieeexplore.ieee.org/document/9413039" style="color: black;" target="_blank">[link]</a>
      
          Minsu Kim, **Joanna Hong**, Junho Kim, Hong Joo Lee, and Yong Man Ro
        
          International Conference on Pattern Recognition **(ICPR), 2021**
         
        - *Comprehensive Facial Expression Synthesis Using Human-Interpretable Language* <a href="https://arxiv.org/abs/2007.08154" style="color: black;" target="_blank">[link]</a>
      
          **Joanna Hong**, Jung Uk Kim, Sangmin Lee, Yong Man Ro
        
          IEEE International Conference on Image Processing **(ICIP), 2020**
         
        - *Learning Style Correlation For Elaborate Few-Shot Classification* <a href="https://ieeexplore.ieee.org/document/9190685" style="color: black;" target="_blank">[link]</a>
      
          Junho Kim, Minsu Kim, Jung Uk Kim, Hong Joo Lee, Sangmin Lee, **Joanna Hong**, Yong Man Ro
        
          IEEE International Conference on Image Processing **(ICIP), 2020**
         
        - *Face Tells Detailed Expression: Generating Comprehensive Facial Expression Sentence Through Facial Action Units* <a href="https://dl.acm.org/doi/abs/10.1007/978-3-030-37734-2_9" style="color: black;" target="_blank">[link]</a>
      
          **Joanna Hong**, Hong Joo Lee, Yelin Kim, and Yong Man Ro
        
          International Conference on Multimedia Modeling **(MMM), 2020**
                
      <mark>International Journal</mark>
      - *Speech Reconstruction with Reminiscent Sound via Visual Voice Memory* <a href="https://ieeexplore.ieee.org/document/9618777" style="color: black;" target="_blank">[link]</a>
      
         **Joanna Hong**, Minsu Kim, Se Jin Park, Yong Man Ro
         
         IEEE/ACM Transactions on Audio, Speech, and Language Processing **(TASLP), 2021**
         
      - *Cromm-vsr: Cross-modal memory augmented visual speech recognition* <a href="https://ieeexplore.ieee.org/abstract/document/9566778" style="color: black;" target="_blank">[link]</a>
      
         Minsu Kim, **Joanna Hong**, Se Jin Park, Yong Man Ro
         
         IEEE Transactions on Multimedia **(TMM), 2021**
         
  - title: Experience
    layout: list
    content:
      - layout: right
        title: Company name
        sub_title: Job title
        caption: Date Range (eg. November 2016 - present)
        link: Link to company (optional)
        quote: >
          Short description of the company (optional)
        description: | # this will include new lines to allow paragraphs
          Description of role
  - title: Education
    layout: list
    content:
      - layout: top-right
        title: Institution name
        sub_title: Qualifications (eg. BA Performing Arts)
        caption: Date Range (eg. 2016 - 2019)
        quote: >
          Short institution or course description (optional)
        description: | # this will include new lines to allow paragraphs
          Description of qualification
  - title: A Little More About Me
    layout: text
    content: | # this will include new lines to allow paragraphs
      This is where you can write a little more about yourself. You could title this section **Interests** and include some of your other interests.

      Or you could title it **Skills** and write a bit more about things that make you more desirable, like *leadership* or *teamwork*

# Footer
footer_show_references: true
# references_title: References on request (Override references text)

# Build settings
# theme: modern-resume-theme (Use this is you are hosting your resume yourself)
# remote_theme: sproogen/modern-resume-theme (Use this if you are hosting your resume on GitHub)

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag

exclude : [
  "Gemfile",
  "Gemfile.lock",
  "node_modules",
  "vendor/bundle/",
  "vendor/cache/",
  "vendor/gems/",
  "vendor/ruby/",
  "lib/",
  "scripts/",
  "docker-compose.yml",
  ]
